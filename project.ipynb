{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# California Housing Price Prediction\n",
    "Complete Machine Learning Pipeline with Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-display\n",
    "# Dependency installation (if needed)\n",
    "# !pip install shap seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import joblib\n",
    "import shap\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logging.basicConfig(\n",
    "    filename='housing.log',\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading & Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    \"\"\"Robust data loader\"\"\"\n",
    "\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        self.df = None\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"Load and validate data\"\"\"\n",
    "        try:\n",
    "            self.df = pd.read_csv(self.url)\n",
    "            self._clean_data()\n",
    "            logging.info(f\"Data loaded successfully. Shape: {self.df.shape}\")\n",
    "            return self.df\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Data loading failed: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def _clean_data(self):\n",
    "        \"\"\"Data cleaning operations\"\"\"\n",
    "        # Handle missing values\n",
    "        self.df = self.df.dropna(subset=['median_income', 'housing_median_age'])\n",
    "\n",
    "        # Handle outliers\n",
    "        self.df['median_house_value'] = self.df['median_house_value'].clip(upper=500000)\n",
    "\n",
    "        # Ensure valid values\n",
    "        self.df['total_rooms'] = self.df['total_rooms'].replace(0, 1)\n",
    "        self.df['households'] = self.df['households'].replace(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute data loading\n",
    "loader = DataLoader(\"https://raw.githubusercontent.com/ageron/handson-ml2/master/datasets/housing/housing.csv\")\n",
    "df = loader.load_data()\n",
    "\n",
    "# Display basic info\n",
    "print(\"Data shape:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureEngineer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Reusable feature engineering pipeline\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.feature_names_ = []\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"Generate new features\"\"\"\n",
    "        df = X.copy()\n",
    "\n",
    "        # Spatial features (log transformed)\n",
    "        df['rooms_per_household'] = np.log1p(df['total_rooms'] / df['households'])\n",
    "        df['bedrooms_ratio'] = np.log1p(df['total_bedrooms'] / df['total_rooms'])\n",
    "\n",
    "        # Temporal feature\n",
    "        df['house_age'] = 2023 - df['housing_median_age']\n",
    "\n",
    "        # Geographical feature\n",
    "        df['distance_to_coast'] = np.sqrt(\n",
    "            (df['latitude'] - 34.42) ​**​ 2 +\n",
    "            (df['longitude'] + 118.49) ​**​ 2\n",
    "        )\n",
    "\n",
    "        # Feature selection\n",
    "        self.feature_names_ = [\n",
    "            'median_income', 'house_age', 'rooms_per_household',\n",
    "            'bedrooms_ratio', 'distance_to_coast', 'ocean_proximity'\n",
    "        ]\n",
    "        return df[self.feature_names_]\n",
    "\n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        return self.feature_names_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute feature engineering\n",
    "engineer = FeatureEngineer()\n",
    "X = engineer.fit_transform(df)\n",
    "y = df['median_house_value']\n",
    "\n",
    "# Visualize feature distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(X['rooms_per_household'], kde=True)\n",
    "plt.title('Rooms per Household Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SafeOneHotEncoder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Robust categorical encoder\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.categories_ = {}\n",
    "        self.feature_names_out_ = []\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X_df = pd.DataFrame(X)\n",
    "        self.categories_ = {\n",
    "            col: X_df[col].unique().tolist()\n",
    "            for col in X_df.columns\n",
    "        }\n",
    "        self.feature_names_out_ = [\n",
    "            f\"{col}_{cat}\"\n",
    "            for col in X_df.columns\n",
    "            for cat in sorted(self.categories_[col])\n",
    "        ]\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_df = pd.DataFrame(X)\n",
    "        dummies = pd.get_dummies(X_df, prefix_sep='_')\n",
    "        for col in self.feature_names_out_:\n",
    "            if col not in dummies.columns:\n",
    "                dummies[col] = 0\n",
    "        return dummies[self.feature_names_out_]\n",
    "\n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        return self.feature_names_out_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_preprocessor():\n",
    "    \"\"\"Construct preprocessing pipeline\"\"\"\n",
    "    num_features = ['median_income', 'house_age',\n",
    "                    'rooms_per_household', 'bedrooms_ratio',\n",
    "                    'distance_to_coast']\n",
    "\n",
    "    num_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    cat_pipeline = Pipeline([\n",
    "        ('onehot', SafeOneHotEncoder())\n",
    "    ])\n",
    "\n",
    "    return ColumnTransformer([\n",
    "        ('num', num_pipeline, num_features),\n",
    "        ('cat', cat_pipeline, ['ocean_proximity'])\n",
    "    ])\n",
    "\n",
    "# Initialize preprocessor\n",
    "preprocessor = build_preprocessor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Training & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data splitting\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Data preprocessing\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "# Get feature names\n",
    "num_features = ['median_income', 'house_age', \n",
    "                'rooms_per_household', 'bedrooms_ratio', 'distance_to_coast']\n",
    "cat_features = preprocessor.named_transformers_['cat'].named_steps['onehot'].get_feature_names_out()\n",
    "all_features = num_features + cat_features\n",
    "\n",
    "print(\"Final feature count:\", len(all_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train, y_train):\n",
    "    \"\"\"Model training with hyperparameter tuning\"\"\"\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200],\n",
    "        'max_depth': [5, 10],\n",
    "        'min_samples_split': [2, 5]\n",
    "    }\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=RandomForestRegressor(random_state=42),\n",
    "        param_grid=param_grid,\n",
    "        cv=5,\n",
    "        scoring='neg_mean_absolute_error',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    logging.info(f\"Best parameters: {grid_search.best_params_}\")\n",
    "    return grid_search.best_estimator_\n",
    "\n",
    "# Train model\n",
    "model = train_model(X_train_processed, y_train)\n",
    "print(\"Best model parameters:\", model.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model evaluation\n",
    "y_pred = model.predict(X_test_processed)\n",
    "\n",
    "print(\"\\n=== Model Performance ===\")\n",
    "print(f\"MAE: ${mean_absolute_error(y_test, y_pred):,.0f}\")\n",
    "print(f\"R²: {r2_score(y_test, y_pred):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Results Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_results(model, X_test, feature_names):\n",
    "    \"\"\"Generate SHAP explanation plots\"\"\"\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    shap.summary_plot(shap_values, X_test, feature_names=feature_names)\n",
    "    plt.savefig('feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Generate visualizations\n",
    "visualize_results(model, X_test_processed, all_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save models\n",
    "joblib.dump(model, 'final_model.pkl')\n",
    "joblib.dump(preprocessor, 'preprocessor.pkl')\n",
    "\n",
    "print(\"Saved model files:\")\n",
    "!ls -lh *.pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Log Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tail -n 20 housing.log"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 }
}